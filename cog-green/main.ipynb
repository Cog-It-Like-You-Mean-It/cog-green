{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfe6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338fbdbd",
   "metadata": {},
   "source": [
    "## loading and saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4d8431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0dadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory, label):\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = directory + \"/\" + filename\n",
    "        image = plt.imread(file_path)\n",
    "        images.append(image)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_images(\"./data/trash\", 0)\n",
    "load_images(\"./data/paper-recycling\", 1)\n",
    "load_images(\"./data/other-recycling\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "628203ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"images.npy\", np.array(images))\n",
    "np.save(\"labels.npy\", np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd3b7a",
   "metadata": {},
   "source": [
    "## Preprocessing and Memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffbe0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"./images.npy\", mmap_mode=\"r\")\n",
    "labels = np.load(\"./labels.npy\", mmap_mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346f601a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2527, 384, 512, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0f3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean\n",
    "batch_size = int(len(labels) / 4)\n",
    "sum_ = 0\n",
    "for cnt in range(4):\n",
    "    total = images[cnt * batch_size:(cnt + 1) * batch_size].sum(axis=0)\n",
    "    sum_ += total\n",
    "mean_images = sum_ / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3c76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute standard deviation\n",
    "total = 0\n",
    "for cnt in range(4):\n",
    "    total += np.sum((images[cnt * batch_size:(cnt + 1) * batch_size] - mean_images) ** 2, axis=0)\n",
    "std_images = np.sqrt(total / len(labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09826b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean and std\n",
    "np.save(\"./image_stats.npy\", (np.array(mean_images), np.array(std_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d6c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_images, std_images = np.load(\"./image_stats.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27b6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize all images\n",
    "batch_size = int(len(labels) / 4)\n",
    "normed_images = np.empty((2527, 3, 384, 512))\n",
    "for cnt in range(4):\n",
    "    normed_images[cnt * batch_size:(cnt + 1) * batch_size] = ((images[cnt * batch_size:(cnt + 1) * batch_size] - mean_images) / std_images).transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7beecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[[[226, 198, 186],\n",
       "          [226, 198, 186],\n",
       "          [226, 198, 186],\n",
       "          ...,\n",
       "          [192, 172, 161],\n",
       "          [192, 172, 161],\n",
       "          [192, 172, 161]],\n",
       "\n",
       "         [[226, 198, 186],\n",
       "          [226, 198, 186],\n",
       "          [226, 198, 186],\n",
       "          ...,\n",
       "          [193, 173, 162],\n",
       "          [192, 172, 161],\n",
       "          [192, 172, 161]],\n",
       "\n",
       "         [[226, 198, 186],\n",
       "          [226, 198, 186],\n",
       "          [226, 198, 186],\n",
       "          ...,\n",
       "          [193, 173, 162],\n",
       "          [193, 173, 162],\n",
       "          [192, 172, 161]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[218, 191, 180],\n",
       "          [218, 191, 180],\n",
       "          [218, 191, 180],\n",
       "          ...,\n",
       "          [158, 139, 132],\n",
       "          [157, 138, 131],\n",
       "          [157, 138, 131]],\n",
       "\n",
       "         [[218, 192, 179],\n",
       "          [218, 192, 179],\n",
       "          [218, 192, 179],\n",
       "          ...,\n",
       "          [158, 139, 132],\n",
       "          [157, 138, 131],\n",
       "          [157, 138, 131]],\n",
       "\n",
       "         [[218, 192, 179],\n",
       "          [218, 192, 179],\n",
       "          [218, 192, 179],\n",
       "          ...,\n",
       "          [158, 139, 132],\n",
       "          [157, 138, 131],\n",
       "          [157, 138, 131]]],\n",
       "\n",
       "\n",
       "        [[[222, 208, 197],\n",
       "          [222, 208, 197],\n",
       "          [222, 208, 197],\n",
       "          ...,\n",
       "          [227, 214, 205],\n",
       "          [227, 214, 205],\n",
       "          [226, 213, 204]],\n",
       "\n",
       "         [[222, 208, 197],\n",
       "          [222, 208, 197],\n",
       "          [222, 208, 197],\n",
       "          ...,\n",
       "          [227, 214, 205],\n",
       "          [227, 214, 205],\n",
       "          [226, 213, 204]],\n",
       "\n",
       "         [[222, 208, 197],\n",
       "          [222, 208, 197],\n",
       "          [222, 208, 197],\n",
       "          ...,\n",
       "          [227, 214, 205],\n",
       "          [227, 214, 205],\n",
       "          [226, 213, 204]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[220, 206, 195],\n",
       "          [220, 206, 195],\n",
       "          [220, 206, 195],\n",
       "          ...,\n",
       "          [ 93,  85,  74],\n",
       "          [ 93,  85,  74],\n",
       "          [ 93,  85,  74]],\n",
       "\n",
       "         [[220, 206, 195],\n",
       "          [220, 206, 195],\n",
       "          [220, 206, 195],\n",
       "          ...,\n",
       "          [ 93,  85,  74],\n",
       "          [ 93,  85,  74],\n",
       "          [ 93,  85,  74]],\n",
       "\n",
       "         [[220, 206, 195],\n",
       "          [220, 206, 195],\n",
       "          [220, 206, 195],\n",
       "          ...,\n",
       "          [ 93,  85,  74],\n",
       "          [ 93,  85,  74],\n",
       "          [ 93,  85,  74]]],\n",
       "\n",
       "\n",
       "        [[[171, 144, 135],\n",
       "          [171, 144, 135],\n",
       "          [171, 144, 135],\n",
       "          ...,\n",
       "          [161, 140, 123],\n",
       "          [161, 140, 123],\n",
       "          [161, 140, 123]],\n",
       "\n",
       "         [[171, 144, 135],\n",
       "          [171, 144, 135],\n",
       "          [171, 144, 135],\n",
       "          ...,\n",
       "          [161, 140, 123],\n",
       "          [161, 140, 123],\n",
       "          [161, 140, 123]],\n",
       "\n",
       "         [[171, 144, 135],\n",
       "          [171, 144, 135],\n",
       "          [171, 144, 135],\n",
       "          ...,\n",
       "          [161, 140, 123],\n",
       "          [161, 140, 123],\n",
       "          [161, 140, 123]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[157, 135, 122],\n",
       "          [157, 135, 122],\n",
       "          [157, 135, 122],\n",
       "          ...,\n",
       "          [129, 111, 101],\n",
       "          [129, 111, 101],\n",
       "          [129, 111, 101]],\n",
       "\n",
       "         [[155, 133, 120],\n",
       "          [156, 134, 121],\n",
       "          [157, 135, 122],\n",
       "          ...,\n",
       "          [129, 111, 101],\n",
       "          [129, 111, 101],\n",
       "          [129, 111, 101]],\n",
       "\n",
       "         [[154, 132, 119],\n",
       "          [156, 134, 121],\n",
       "          [158, 136, 123],\n",
       "          ...,\n",
       "          [129, 111, 101],\n",
       "          [129, 111, 101],\n",
       "          [129, 111, 101]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[202, 185, 169],\n",
       "          [202, 185, 169],\n",
       "          [202, 185, 169],\n",
       "          ...,\n",
       "          [ 54,  46,  35],\n",
       "          [ 55,  47,  36],\n",
       "          [ 55,  47,  36]],\n",
       "\n",
       "         [[202, 185, 169],\n",
       "          [202, 185, 169],\n",
       "          [202, 185, 169],\n",
       "          ...,\n",
       "          [ 54,  46,  35],\n",
       "          [ 55,  47,  36],\n",
       "          [ 56,  48,  37]],\n",
       "\n",
       "         [[202, 185, 169],\n",
       "          [202, 185, 169],\n",
       "          [202, 185, 169],\n",
       "          ...,\n",
       "          [ 55,  47,  36],\n",
       "          [ 56,  48,  37],\n",
       "          [ 56,  48,  37]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[209, 191, 177],\n",
       "          [209, 191, 177],\n",
       "          [209, 191, 177],\n",
       "          ...,\n",
       "          [168, 155, 139],\n",
       "          [168, 155, 138],\n",
       "          [168, 155, 138]],\n",
       "\n",
       "         [[209, 191, 177],\n",
       "          [209, 191, 177],\n",
       "          [209, 191, 177],\n",
       "          ...,\n",
       "          [167, 154, 138],\n",
       "          [167, 154, 137],\n",
       "          [167, 154, 137]],\n",
       "\n",
       "         [[209, 191, 177],\n",
       "          [209, 191, 177],\n",
       "          [209, 191, 177],\n",
       "          ...,\n",
       "          [167, 154, 138],\n",
       "          [167, 154, 137],\n",
       "          [167, 154, 137]]],\n",
       "\n",
       "\n",
       "        [[[196, 196, 208],\n",
       "          [197, 197, 209],\n",
       "          [197, 197, 209],\n",
       "          ...,\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157]],\n",
       "\n",
       "         [[196, 196, 208],\n",
       "          [197, 197, 209],\n",
       "          [197, 197, 209],\n",
       "          ...,\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157]],\n",
       "\n",
       "         [[196, 196, 208],\n",
       "          [196, 196, 208],\n",
       "          [197, 197, 209],\n",
       "          ...,\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[190, 190, 202],\n",
       "          [189, 189, 201],\n",
       "          [189, 189, 201],\n",
       "          ...,\n",
       "          [152, 153, 158],\n",
       "          [152, 153, 158],\n",
       "          [151, 152, 157]],\n",
       "\n",
       "         [[190, 190, 202],\n",
       "          [190, 190, 202],\n",
       "          [189, 189, 201],\n",
       "          ...,\n",
       "          [152, 153, 158],\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157]],\n",
       "\n",
       "         [[190, 190, 202],\n",
       "          [190, 190, 202],\n",
       "          [190, 190, 202],\n",
       "          ...,\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157],\n",
       "          [151, 152, 157]]],\n",
       "\n",
       "\n",
       "        [[[197, 199, 214],\n",
       "          [197, 199, 214],\n",
       "          [197, 199, 214],\n",
       "          ...,\n",
       "          [148, 150, 163],\n",
       "          [148, 150, 163],\n",
       "          [148, 150, 163]],\n",
       "\n",
       "         [[197, 199, 214],\n",
       "          [197, 199, 214],\n",
       "          [197, 199, 214],\n",
       "          ...,\n",
       "          [148, 150, 163],\n",
       "          [148, 150, 163],\n",
       "          [148, 150, 163]],\n",
       "\n",
       "         [[197, 199, 214],\n",
       "          [197, 199, 214],\n",
       "          [197, 199, 214],\n",
       "          ...,\n",
       "          [148, 150, 163],\n",
       "          [148, 150, 163],\n",
       "          [148, 150, 163]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[200, 202, 217],\n",
       "          [200, 202, 217],\n",
       "          [200, 202, 217],\n",
       "          ...,\n",
       "          [127, 129, 142],\n",
       "          [127, 129, 142],\n",
       "          [127, 129, 142]],\n",
       "\n",
       "         [[200, 202, 217],\n",
       "          [200, 202, 217],\n",
       "          [200, 202, 217],\n",
       "          ...,\n",
       "          [127, 129, 142],\n",
       "          [127, 129, 142],\n",
       "          [127, 129, 142]],\n",
       "\n",
       "         [[200, 202, 217],\n",
       "          [200, 202, 217],\n",
       "          [200, 202, 217],\n",
       "          ...,\n",
       "          [127, 129, 142],\n",
       "          [127, 129, 142],\n",
       "          [127, 129, 142]]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose to fix dimensions\n",
    "normed_images = normed_images.transpose(0,3,1,2).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1626e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save normed images\n",
    "np.save(\"./normed_images.npy\", normed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994acd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2527, 384, 512, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc63b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_images = np.load(\"./transposed.npy\", mmap_mode = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e785204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[[ 0.36677116,  0.3661065 ,  0.36512186, ...,  0.27039764,\n",
       "           0.27238152,  0.27890733],\n",
       "         [ 0.36729593,  0.36576731,  0.36500429, ...,  0.29203913,\n",
       "           0.27121179,  0.27730878],\n",
       "         [ 0.36736351,  0.3676344 ,  0.36444181, ...,  0.29260927,\n",
       "           0.29622656,  0.27614072],\n",
       "         ...,\n",
       "         [ 0.33646927,  0.33946624,  0.33848228, ..., -0.0710815 ,\n",
       "          -0.09063637, -0.0878033 ],\n",
       "         [ 0.34042793,  0.33944773,  0.33982424, ..., -0.07376808,\n",
       "          -0.0922981 , -0.08694377],\n",
       "         [ 0.34239324,  0.34288857,  0.33954156, ..., -0.07556355,\n",
       "          -0.09475904, -0.08929157]],\n",
       "\n",
       "        [[-0.09278396, -0.09834652, -0.0998483 , ...,  0.01056183,\n",
       "           0.01329295,  0.01935507],\n",
       "         [-0.09282432, -0.09480796, -0.09548613, ...,  0.0314546 ,\n",
       "           0.01129014,  0.01698485],\n",
       "         [-0.09284611, -0.09244363, -0.09712148, ...,  0.03214142,\n",
       "           0.03553001,  0.01598746],\n",
       "         ...,\n",
       "         [-0.10115274, -0.09909566, -0.10010277, ..., -0.31766698,\n",
       "          -0.3359228 , -0.33241402],\n",
       "         [-0.07297513, -0.07434086, -0.07454663, ..., -0.32084895,\n",
       "          -0.33860625, -0.33230279],\n",
       "         [-0.06680559, -0.06754319, -0.07150015, ..., -0.32257056,\n",
       "          -0.34175584, -0.33600674]],\n",
       "\n",
       "        [[-0.18150347, -0.18609545, -0.1866691 , ..., -0.07083929,\n",
       "          -0.06801899, -0.06270719],\n",
       "         [-0.18165637, -0.18290198, -0.18268265, ..., -0.05286131,\n",
       "          -0.0702208 , -0.06525835],\n",
       "         [-0.18168523, -0.18083367, -0.18419688, ..., -0.05287773,\n",
       "          -0.04985474, -0.06686543],\n",
       "         ...,\n",
       "         [-0.17728647, -0.17591738, -0.1767534 , ..., -0.28191143,\n",
       "          -0.29882989, -0.29599708],\n",
       "         [-0.19151305, -0.19283969, -0.19335965, ..., -0.28455844,\n",
       "          -0.30070682, -0.29540772],\n",
       "         [-0.18496911, -0.18598526, -0.18960474, ..., -0.28580604,\n",
       "          -0.30320378, -0.29806698]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b557c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"./labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0f127",
   "metadata": {},
   "source": [
    "## Train and test data split (not finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161f6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.arange(len(labels))\n",
    "np.random.shuffle(idxs)\n",
    "idxs = idxs\n",
    "train_indices = idxs[0: int(0.75 * len(labels))]\n",
    "test_indices = idxs[int(0.75 * len(labels)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40a267",
   "metadata": {},
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9deb8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "relu = nn.functional.relu\n",
    "cross_entropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b5e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # MyNN's 'dense' layers are PyTorch's 'linear' layers.\n",
    "        # Note that these layers do not accept weight-initialization functions.\n",
    "        self.dense1 = nn.Linear(x_train.shape[1], 100)\n",
    "        #need kernel size and stride\n",
    "        self.CNN = nn.Conv2d(100, 50, 8, 8)\n",
    "        self.dense3 = nn.Linear(50, 3)\n",
    "        \n",
    "        # We have to separately overwrite the weights in the layers with\n",
    "        # the initialization scheme that we desire. Here, we use the\n",
    "        # \"xavier-normal\" initialization scheme for the weights, and \n",
    "        # initialize the biases to 0\n",
    "        # Note that these functions update the weights in-place; this \n",
    "        # is denoted, in pytorch, by the trailing underscore in the\n",
    "        # function name: `xavier_normal_`\n",
    "        # This is merely a convention adopted by PyTorch\n",
    "        for layer in (self.dense1, self.CNN, self.dense3):\n",
    "            nn.init.xavier_normal_(layer.weight, np.sqrt(2))\n",
    "            nn.init.constant_(layer.bias, 0)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward data through the network.\n",
    "        \n",
    "        This allows us to conveniently initialize a model `m` and then send data through it\n",
    "        to be classified by calling `m(x)`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Union[numpy.ndarray, mygrad.Tensor], shape=(N, D)\n",
    "            The data to forward through the network.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape=(N, 1)\n",
    "            The model outputs.\n",
    "        '''\n",
    "        return self.dense3(relu(self.CNN(relu(self.dense1(x)))))\n",
    "    \n",
    "    \n",
    "    \n",
    "def accuracy(predictions, truth):\n",
    "    \"\"\"\n",
    "    Returns the mean classification accuracy for a batch of predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : Union[numpy.ndarray, mg.Tensor], shape=(M, D)\n",
    "        The scores for D classes, for a batch of M data points\n",
    "    truth : numpy.ndarray, shape=(M,)\n",
    "        The true labels for each datum in the batch: each label is an\n",
    "        integer in [0, D)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    if isinstance(predictions, mg.Tensor):\n",
    "        predictions = predictions.data\n",
    "    return np.mean((torch.argmax(prediction, dim=1) == truth).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec116f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will place these tensors in gpu memory, if a gpu is available, otherwise\n",
    "# we will simply use the CPU. It is very unlikely that your laptop has a\n",
    "# GPU for us to leverage.\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d32f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c77382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noggin import create_plot\n",
    "plotter, fig, ax = create_plot(metrics=[\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20abb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our model and place its parameters on the GPU if it is available\n",
    "model =  Model().to(device)\n",
    "\n",
    "# initialize the optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), weight_decay=5E-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = \n",
    "batch_size = \n",
    "\n",
    "for epoch_cnt in range(num_epoch):\n",
    "    for batch_cnt in range(len(train_indices) // batch_size):\n",
    "        \n",
    "        batch_x = transposed_images[train_indices[batch_cnt * batch_size : (batch_cnt + 1) * batch_size]]\n",
    "        batch_y = labels[train_indices[batch_cnt * batch_size : (batch_cnt + 1) * batch_size]]\n",
    "        \n",
    "        x = torch.tensor(batch_x).to(device)\n",
    "        y_true = torch.tensor(batch_y).to(device)\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = cross_entropy(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        acc = accuracy(y_pred, y_true)\n",
    "        \n",
    "        optim.zero_grad()  # this is comparable to `null_gradients` in MyGrad\n",
    "        plotter.set_train_batch({\"loss\" : loss.item(),\n",
    "                                 \"accuracy\" : acc},\n",
    "                                 batch_size=batch_size, plot=False)\n",
    "\n",
    "        \n",
    "        # test_data = torch.tensor(y_train, dtype=torch.int64).to(device)\n",
    "\n",
    "        # X = torch.tensor(x_test).to(device)\n",
    "        # Y = torch.tensor(y_test, dtype=torch.int64).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
